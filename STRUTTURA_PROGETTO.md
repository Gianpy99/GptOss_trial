# ðŸ“‹ STRUTTURA PROGETTO - Ollama_wrapper con Fine-Tuning

## ðŸŒ³ Albero Directory (File Principali)

```
Ollama_wrapper/
â”‚
â”œâ”€â”€ ðŸ“„ README.md                          # README principale (aggiornato)
â”œâ”€â”€ ðŸ“„ FINETUNING_GUIDE.md               # Guida completa fine-tuning (NUOVO)
â”œâ”€â”€ ðŸ“„ FINETUNING_SUMMARY.md             # Riepilogo veloce (NUOVO)
â”œâ”€â”€ ðŸ“„ INTEGRAZIONE_FATTA.md             # Cosa Ã¨ stato aggiunto (NUOVO)
â”œâ”€â”€ ðŸ“„ COMANDI_RAPIDI.md                 # Quick reference (NUOVO)
â”‚
â”œâ”€â”€ ðŸ“„ requirements.txt                  # Dipendenze base
â”œâ”€â”€ ðŸ“„ requirements-finetuning.txt       # Dipendenze fine-tuning (NUOVO)
â”œâ”€â”€ ðŸ“„ pyproject.toml                    # Config progetto (aggiornato)
â”‚
â”œâ”€â”€ ðŸ“„ test_integration.py               # Test integrazione (NUOVO)
â”œâ”€â”€ ðŸ“„ test_wrapper.py                   # Test wrapper base
â”œâ”€â”€ ðŸ“„ demo.py                           # Demo originale
â”‚
â”œâ”€â”€ ðŸ“ src/
â”‚   â””â”€â”€ ðŸ“ ollama_wrapper/
â”‚       â”œâ”€â”€ ðŸ“„ __init__.py               # Exports (aggiornato)
â”‚       â”œâ”€â”€ ðŸ“„ wrapper.py                # Wrapper Ollama originale
â”‚       â””â”€â”€ ðŸ“„ finetuning.py             # Modulo fine-tuning (NUOVO â­)
â”‚
â”œâ”€â”€ ðŸ“ examples/
â”‚   â”œâ”€â”€ ðŸ“„ example.py                            # Esempio base
â”‚   â”œâ”€â”€ ðŸ“„ quick_start_finetuning.py             # Quick start FT (NUOVO)
â”‚   â””â”€â”€ ðŸ“„ example_finetuning_integration.py     # Workflow completo FT (NUOVO)
â”‚
â”œâ”€â”€ ðŸ“ tests/
â”‚   â”œâ”€â”€ ðŸ“ unit/
â”‚   â””â”€â”€ ðŸ“ integration/
â”‚
â””â”€â”€ ðŸ“ ollama_sessions/                  # Sessioni salvate
```

## ðŸ“¦ File Chiave per Fine-Tuning

### Modulo Core
| File | Righe | Descrizione |
|------|-------|-------------|
| `src/ollama_wrapper/finetuning.py` | ~720 | Classe FineTuningManager completa |

### Documentazione
| File | Parole | Descrizione |
|------|--------|-------------|
| `FINETUNING_GUIDE.md` | ~3000 | Guida completa con esempi |
| `FINETUNING_SUMMARY.md` | ~2000 | Overview e quick reference |
| `INTEGRAZIONE_FATTA.md` | ~1500 | Riepilogo integrazione |
| `COMANDI_RAPIDI.md` | ~500 | Comandi e snippet veloci |

### Esempi
| File | Righe | Descrizione |
|------|-------|-------------|
| `examples/quick_start_finetuning.py` | ~100 | Esempio 5 minuti |
| `examples/example_finetuning_integration.py` | ~350 | Workflow completo interattivo |

### Configurazione
| File | Descrizione |
|------|-------------|
| `requirements-finetuning.txt` | 7 dipendenze opzionali |
| `pyproject.toml` | Aggiunta sezione `[project.optional-dependencies]` |
| `src/ollama_wrapper/__init__.py` | Export FineTuningManager e create_finetuned_assistant |

## ðŸ”‘ Componenti Principali

### 1. FineTuningManager (`src/ollama_wrapper/finetuning.py`)

**Metodi Pubblici:**
- `__init__(model_name, output_dir, memory_db_path, use_4bit)`
- `load_model(load_in_4bit, device_map, torch_dtype)`
- `setup_lora(r, lora_alpha, lora_dropout, target_modules, bias)`
- `load_training_data_from_memory(session_ids, min_length, format_style)`
- `load_training_data_from_json(json_path, format_style)`
- `tokenize_dataset(dataset, max_length, remove_columns)`
- `train(train_dataset, eval_dataset, num_epochs, batch_size, ...)`
- `save_adapter(adapter_name)`
- `load_adapter(adapter_path)`
- `generate_text(prompt, max_new_tokens, temperature, ...)`
- `export_to_gguf(output_path, quantization)` [planned]

**Funzioni Helper:**
- `_format_conversation(messages, style)`
- `create_finetuned_assistant(adapter_path, base_model, **kwargs)`

### 2. Integrazione con OllamaWrapper

**Come Funziona:**
```python
# OllamaWrapper salva conversazioni â†’ SQLite
wrapper = OllamaWrapper(session_id="training")
wrapper.chat("domanda")  # â†’ ollama_memory.db

# FineTuningManager legge da SQLite
manager = FineTuningManager(memory_db_path="ollama_memory.db")
dataset = manager.load_training_data_from_memory()  # â† ollama_memory.db

# Training usa dati reali dalle conversazioni!
manager.train(dataset)
```

## ðŸ“Š Statistiche Codice

### Righe di Codice
- **Nuovo codice**: ~1200 righe
  - `finetuning.py`: ~720 righe
  - Esempi: ~450 righe
  - Test: ~30 righe

### Documentazione
- **Nuova documentazione**: ~7000 parole
  - Guide: ~5500 parole
  - Commenti codice: ~1500 parole

### Copertura
- âœ… Caricamento modelli (Hugging Face)
- âœ… Configurazione PEFT/LoRA
- âœ… Training con Trainer API
- âœ… Salvataggio/caricamento adapters
- âœ… Generazione testo
- âœ… Integrazione memoria SQLite
- âœ… Supporto JSON
- âœ… Multiple data formats
- âœ… Error handling completo
- âœ… Documentazione estensiva

## ðŸŽ¯ FunzionalitÃ  per Use Case

### Use Case 1: Fine-Tune da Conversazioni Ollama
**File Coinvolti:**
1. `src/ollama_wrapper/wrapper.py` - Crea conversazioni
2. `ollama_memory.db` - Storage conversazioni
3. `src/ollama_wrapper/finetuning.py` - Fine-tuning
4. `examples/example_finetuning_integration.py` - Esempio completo

### Use Case 2: Fine-Tune da JSON Custom
**File Coinvolti:**
1. Tuo file JSON con dati
2. `src/ollama_wrapper/finetuning.py` - Fine-tuning
3. `examples/quick_start_finetuning.py` - Esempio base

### Use Case 3: Workflow Ibrido
**File Coinvolti:**
1. `src/ollama_wrapper/wrapper.py` - Ollama per generale
2. `src/ollama_wrapper/finetuning.py` - Fine-tuned per specializzato
3. Custom router logic

## ðŸš€ Come Navigare il Progetto

### Per Iniziare
1. Leggi `README.md` (sezione fine-tuning)
2. Leggi `FINETUNING_SUMMARY.md`
3. Esegui `python test_integration.py`

### Per Implementare
1. Leggi `FINETUNING_GUIDE.md` completo
2. Esegui `python examples/quick_start_finetuning.py`
3. Studia `src/ollama_wrapper/finetuning.py`

### Per Personalizzare
1. Copia `examples/example_finetuning_integration.py`
2. Modifica per il tuo use case
3. Consulta docstrings in `finetuning.py`

### Per Troubleshooting
1. Sezione Troubleshooting in `FINETUNING_GUIDE.md`
2. Controlla `test_integration.py`
3. Verifica `COMANDI_RAPIDI.md`

## ðŸ“š Dipendenze

### Base (requirements.txt)
```
requests>=2.25.0
```

### Fine-Tuning (requirements-finetuning.txt)
```
transformers>=4.35.0
peft>=0.7.0
torch>=2.1.0
datasets>=2.15.0
accelerate>=0.25.0
bitsandbytes>=0.41.0
```

### Optional in pyproject.toml
```toml
[project.optional-dependencies]
finetuning = [
    "transformers>=4.35.0",
    "peft>=0.7.0",
    ...
]
```

## ðŸ§ª Test

### Test Esistenti
- `test_wrapper.py` - Test wrapper base
- `test_complete.py` - Test completi
- `tests/unit/` - Test unitari
- `tests/integration/` - Test integrazione

### Test Nuovi
- `test_integration.py` - Test integrazione fine-tuning

## ðŸ“– Ordine di Lettura Consigliato

### Per Utenti
1. `README.md` â†’ Sezione fine-tuning
2. `FINETUNING_SUMMARY.md`
3. `examples/quick_start_finetuning.py` (run it!)
4. `FINETUNING_GUIDE.md`
5. `examples/example_finetuning_integration.py`

### Per Sviluppatori
1. `INTEGRAZIONE_FATTA.md`
2. `src/ollama_wrapper/finetuning.py` (leggi docstrings)
3. `examples/example_finetuning_integration.py` (studia codice)
4. `FINETUNING_GUIDE.md` â†’ Advanced Features

### Quick Reference
- `COMANDI_RAPIDI.md` - Sempre a portata di mano!

## ðŸŽ‰ Prossimi Passi Suggeriti

1. âœ… Esplora struttura progetto
2. âœ… Installa dipendenze: `pip install -r requirements-finetuning.txt`
3. âœ… Test: `python test_integration.py`
4. âœ… Quick start: `python examples/quick_start_finetuning.py`
5. âœ… Leggi documentazione completa
6. âœ… Crea il tuo primo adapter!

---

**Progetto completamente integrato e pronto all'uso! ðŸš€**
