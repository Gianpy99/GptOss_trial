data_path: "path/to/your/dataset"
validation_split: 0.2
batch_size: 32
shuffle: true
num_workers: 4
preprocessing:
  normalize: true
  tokenization:
    method: "wordpiece"
    vocab_file: "path/to/vocab/file"