# ğŸï¸ Demo F1 Fine-Tuning - Guida Rapida

## âœ… File Creati

1. **`demo_f1_finetuning.py`** - Demo completa interattiva
   - Scarica dataset F1
   - Crea training data
   - Testa PRIMA del fine-tuning
   - Esegue fine-tuning
   - Testa DOPO il fine-tuning
   - Confronta i risultati

2. **`test_f1_quick.py`** - Test veloce
   - Versione semplificata
   - Training piÃ¹ veloce
   - Ideale per test rapidi

3. **`F1_DEMO_README.md`** - Documentazione completa
   - Spiegazione dettagliata
   - Configurazione
   - Troubleshooting
   - Personalizzazione

4. **`test_f1_dataset.py`** - Test connessione dataset

## ğŸš€ Come Eseguire

### Opzione 1: Demo Completa (Raccomandato)

```powershell
python demo_f1_finetuning.py
```

**Cosa succede:**
1. Scarica 100 righe da Hugging Face Formula_1_Dataset
2. Crea ~50 esempi di training (domande su piloti/team/tempi)
3. Carica modello base (phi-2)
4. Fa 4 domande al modello base â†’ Risposte generiche/errate
5. Fine-tune il modello (3 epoche, ~10 minuti)
6. Fa le STESSE 4 domande al modello fine-tuned â†’ Risposte accurate!
7. Mostra confronto prima/dopo

**Domande di Test:**
- "What team does VER drive for in Formula 1?"
- "Which drivers race for Red Bull Racing?"
- "What is VER's average lap time?"
- "Who is the fastest driver based on lap times?"

### Opzione 2: Test Veloce

```powershell
python test_f1_quick.py
```

**PiÃ¹ veloce (~5 min):**
- Solo 20 esempi
- 2 epoche
- Configurazione LoRA piÃ¹ leggera

## ğŸ“Š Risultati Attesi

### PRIMA del Fine-Tuning
```
Q: What team does VER drive for in Formula 1?
A: VER could refer to various things. Without more context,
   I cannot provide a specific answer about Formula 1 teams...
```
*(Risposta generica, non sa chi Ã¨ VER)*

### DOPO il Fine-Tuning
```
Q: What team does VER drive for in Formula 1?
A: VER drives for Red Bull Racing in Formula 1.
```
*(Risposta precisa e accurata!)*

## ğŸ¯ Dimostrazione Chiave

La demo dimostra che:

1. **Specializzazione**: Il modello impara conoscenze specifiche (F1)
2. **Efficienza**: Adapter di soli ~20 MB vs 3 GB modello completo
3. **VelocitÃ **: Training in ~10 minuti con dati reali
4. **PraticitÃ **: Usa dati pubblici da Hugging Face

## ğŸ”§ Requisiti

```powershell
# Installa dipendenze (se non fatto)
pip install -r requirements-finetuning.txt

# Verifica dataset accessibile
python test_f1_dataset.py
```

**Hardware:**
- GPU raccomandato (RTX 3090: ~5 min, GTX 1080: ~15 min)
- ~8 GB RAM GPU con QLoRA 4-bit
- CPU possibile ma molto piÃ¹ lento

## ğŸ“ Output Generato

Dopo l'esecuzione troverai:

```
f1_training_data.json              # Dati di training generati
fine_tuned_models/
  â””â”€â”€ f1_expert_adapter/           # Adapter fine-tuned (~20 MB)
      â”œâ”€â”€ adapter_config.json
      â”œâ”€â”€ adapter_model.bin
      â””â”€â”€ ...
```

## ğŸ”„ Riusare l'Adapter

```python
from ollama_wrapper import create_finetuned_assistant

# Carica l'adapter F1
f1_expert = create_finetuned_assistant(
    "./fine_tuned_models/f1_expert_adapter",
    temperature=0.7
)

# Fai domande su F1
response = f1_expert.generate_text(
    "User: Tell me about Max Verstappen's team\n\nAssistant:"
)
print(response)
```

## ğŸ’¡ Personalizzazione

### PiÃ¹ Dati
```python
# In demo_f1_finetuning.py, riga ~50:
rows = download_f1_dataset(limit=200)  # Aumenta a 200
```

### Diverse Domande
```python
# Modifica test_questions (riga ~185):
test_questions = [
    "What is the average track temperature?",
    "How does rainfall affect performance?",
    "Which team has the fastest average lap time?",
]
```

### Training PiÃ¹ Lungo
```python
# In finetune_on_f1_data(), riga ~245:
manager.train(
    num_epochs=5,        # Aumenta epoche
    batch_size=4,        # Aumenta batch se hai memoria
)
```

## ğŸ› Troubleshooting

### Dataset Non Scaricato
```
âŒ Error downloading dataset
```
â†’ Controlla internet, riprova dopo qualche minuto

### Out of Memory
```
âŒ CUDA out of memory
```
â†’ Usa `test_f1_quick.py` (configurazione piÃ¹ leggera)
â†’ Oppure riduci batch_size a 1

### Training Lento
â†’ Normale su CPU/GPU lente
â†’ Usa `test_f1_quick.py` per versione veloce
â†’ Riduci num_epochs a 2

## ğŸ“š Documentazione Completa

Leggi `F1_DEMO_README.md` per:
- Spiegazione dettagliata del codice
- Struttura dataset
- Configurazioni avanzate
- Use case reali
- Best practices

## ğŸ¯ Prossimi Passi

1. âœ… Esegui la demo: `python demo_f1_finetuning.py`
2. âœ… Osserva il miglioramento prima/dopo
3. âœ… Leggi `F1_DEMO_README.md` per dettagli
4. âœ… Personalizza con tue domande
5. âœ… Applica lo stesso approccio al tuo dominio!

## ğŸŒŸ ApplicabilitÃ 

Questo approccio funziona per QUALSIASI dominio:
- ğŸ“Š Dati finanziari
- ğŸ¥ Dati medici
- ğŸ“š Knowledge base aziendali
- ğŸ›’ Cataloghi prodotti
- ğŸ“ Documentazione tecnica
- ğŸ’¬ FAQ e supporto
- ... qualsiasi dataset strutturato!

## ğŸ Esegui Ora!

```powershell
# Demo completa (10-15 min)
python demo_f1_finetuning.py

# O test veloce (5 min)
python test_f1_quick.py
```

**Preparati a vedere la magia del fine-tuning! ğŸï¸ğŸ’¨**

---

## ğŸ“ Hai Problemi?

1. Controlla `F1_DEMO_README.md` â†’ Sezione Troubleshooting
2. Verifica requisiti: `python test_integration.py`
3. Testa dataset: `python test_f1_dataset.py`
4. Leggi errori nel terminale

## âœ¨ Risultato Finale

Avrai dimostrato che:
- âœ… Il modello base NON conosce i dettagli F1
- âœ… Dopo fine-tuning, il modello Ã¨ un esperto F1
- âœ… Tutto con solo ~20 MB di adapter
- âœ… Training in pochi minuti
- âœ… Approach riutilizzabile per qualsiasi dominio

**Buon fine-tuning! ğŸš€**
